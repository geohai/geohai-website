<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-MK50YGPJPH"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-MK50YGPJPH');
</script>

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  


























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Blog | GeoHAI</title>

<link rel="icon" href="/images/icon.png">

<meta name="title" content="Blog">
<meta name="description" content="Geospatial Human-Centered Artificial Intelligence Research Lab. Advancing geospatial use-inspired research at the intersection of AI and human-centered design">

<meta property="og:title" content="Blog">
<meta property="og:site_title" content="GeoHAI">
<meta property="og:description" content="Geospatial Human-Centered Artificial Intelligence Research Lab. Advancing geospatial use-inspired research at the intersection of AI and human-centered design">
<meta property="og:url" content="">
<meta property="og:image" content="/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="Blog">
<meta property="twitter:description" content="Geospatial Human-Centered Artificial Intelligence Research Lab. Advancing geospatial use-inspired research at the intersection of AI and human-centered design">
<meta property="twitter:url" content="">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/images/share.jpg">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "Blog",
    "description": "Geospatial Human-Centered Artificial Intelligence Research Lab. Advancing geospatial use-inspired research at the intersection of AI and human-centered design",
    "headline": "Blog",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/images/icon.png" }
    },
    "url": ""
  }
</script>

<link rel="alternate" type="application/rss+xml" href="/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.7.1/css/all.css" rel="preload" as="style" onload="this.onload = null; this.rel = 'stylesheet';">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.7.1/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/_styles/all.css" rel="stylesheet">
  

  
    <link href="/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/_styles/background.css" rel="stylesheet">
  

  
    <link href="/_styles/body.css" rel="stylesheet">
  

  
    <link href="/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/_styles/button.css" rel="stylesheet">
  

  
    <link href="/_styles/card.css" rel="stylesheet">
  

  
    <link href="/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/_styles/code.css" rel="stylesheet">
  

  
    <link href="/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/_styles/float.css" rel="stylesheet">
  

  
    <link href="/_styles/font.css" rel="stylesheet">
  

  
    <link href="/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/_styles/form.css" rel="stylesheet">
  

  
    <link href="/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/_styles/header.css" rel="stylesheet">
  

  
    <link href="/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/_styles/image.css" rel="stylesheet">
  

  
    <link href="/_styles/link.css" rel="stylesheet">
  

  
    <link href="/_styles/list.css" rel="stylesheet">
  

  
    <link href="/_styles/main.css" rel="stylesheet">
  

  
    <link href="/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/_styles/project-excerpt.css" rel="stylesheet">
  

  
    <link href="/_styles/project-info.css" rel="stylesheet">
  

  
    <link href="/_styles/project-nav.css" rel="stylesheet">
  

  
    <link href="/_styles/project-portrait.css" rel="stylesheet">
  

  
    <link href="/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/_styles/rectangular-grid.css" rel="stylesheet">
  

  
    <link href="/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/_styles/section.css" rel="stylesheet">
  

  
    <link href="/_styles/table.css" rel="stylesheet">
  

  
    <link href="/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/_scripts/anchors.js"></script>

  <script src="/_scripts/dark-mode.js"></script>

  <script src="/_scripts/fetch-tags.js"></script>

  <script src="/_scripts/search.js"></script>

  <script src="/_scripts/site-search.js"></script>

  <script src="/_scripts/tooltip.js"></script>


</head>

  <body>
    









<header class="background" style="background-color: #051B2B;" data-dark="true">
  <a href="/" class="home">
    
      <span class="logo logo-header">
        <img src="/images/icon.png" alt="logo">
        <img class="logo-name-1" src="/images/logo-name-1.png" alt="GEOHAI">
        <img class="logo-name-2" src="/images/logo-name-2.png" alt="Research Lab">
      </span>
    
    
      <span class="title" data-tooltip="Home">
        
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/projects/" data-tooltip="Project descriptions">
          Projects
        </a>
      
    
      
        <a href="/research/" data-tooltip="Published works">
          Publications
        </a>
      
    
      
        <a href="/products/" data-tooltip="Software, datasets, and more">
          Products
        </a>
      
    
      
        <a href="/blog/" data-tooltip="Musings and miscellany">
          Blog
        </a>
      
    
      
        <a href="/team/" data-tooltip="About our team">
          Team
        </a>
      
    
      
        <a href="/contact/" data-tooltip="Email, address, and location">
          Contact
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - wrap each table in div to allow for scrolling
  - filter out blank sections
-->








  
  
  

  <section class="background" data-size="page">
    <h1 id="blog">
<i class="icon fa-solid fa-feather-pointed"></i>Blog</h1>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<div class="search-box">
  <input type="text" class="search-input" oninput="onSearchInput(this)" placeholder="Search items on this page">
  <button disabled data-tooltip="Clear search" aria-label="clear search" onclick="onSearchClear()">
    <i class="icon fa-solid fa-magnifying-glass"></i>
  </button>
</div>

<div class="tags" data-link="/blog/">
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('spatiotemporal')" data-tooltip='Show items with the tag "spatiotemporal"'>
        spatiotemporal
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('machine learning')" data-tooltip='Show items with the tag "machine learning"'>
        machine learning
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('COVID-19')" data-tooltip='Show items with the tag "COVID-19"'>
        COVID-19
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('public health')" data-tooltip='Show items with the tag "public health"'>
        public health
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('epidemiology')" data-tooltip='Show items with the tag "epidemiology"'>
        epidemiology
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('remote sensing')" data-tooltip='Show items with the tag "remote sensing"'>
        remote sensing
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('air pollution')" data-tooltip='Show items with the tag "air pollution"'>
        air pollution
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('foundation model')" data-tooltip='Show items with the tag "foundation model"'>
        foundation model
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('earth embeddings')" data-tooltip='Show items with the tag "earth embeddings"'>
        earth embeddings
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('sea ice')" data-tooltip='Show items with the tag "sea ice"'>
        sea ice
      </a>
    
  </div>

<div class="search-info"></div>

<h3 id="2026">2026</h3>

<div class="post-excerpt">
  
  
  <a href="/2026/02/08/geolocation-for-deep-learning.html">Rethinking Geolocation Features in Deep Learning and Geospatial Applications</a>

  <div class="post-info">
  
    
    
      

<div class="portrait-wrapper">
  <a href="/members/morteza-karimzadeh.html" class="portrait" data-style="tiny" aria-label="Morteza Karimzadeh">
    <img src="/images/member-images/morteza-karimzadeh.jpg" class="portrait-image" alt="member portrait" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">

    
      <span class="portrait-text">
        
          <span class="portrait-name">
            Morteza Karimzadeh
          </span>
        

        
          <span class="portrait-role">
            
            <i class="icon fa-solid fa-microscope"></i>
            <span>Director</span>
          </span>
        
      </span>
    
  </a>
</div>

    
  

  
  

  
    <span data-tooltip="Originally published on">
      <i class="icon fa-regular fa-calendar"></i>
      <span>February 08, 2026</span>
    </span>
  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>February 10, 2026</span>
    </span>
  
</div>


  


  <div class="tags" data-link="/blog">
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('spatiotemporal')" data-tooltip='Show items with the tag "spatiotemporal"'>
        spatiotemporal
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('machine learning')" data-tooltip='Show items with the tag "machine learning"'>
        machine learning
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('remote sensing')" data-tooltip='Show items with the tag "remote sensing"'>
        remote sensing
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('air pollution')" data-tooltip='Show items with the tag "air pollution"'>
        air pollution
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('sea ice')" data-tooltip='Show items with the tag "sea ice"'>
        sea ice
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('foundation model')" data-tooltip='Show items with the tag "foundation model"'>
        foundation model
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('earth embeddings')" data-tooltip='Show items with the tag "earth embeddings"'>
        earth embeddings
      </a>
    
  </div>





  
  
  <p data-search="Most labeled datasets for environmental and geospatial applications  especially those that represent true  ground truth  from field measurements  are collected in fairly limited regions  Whether I am reading research papers or reviewing student proposals in my machine learning and spatial data class  I see one common mistake  adding latitude and longitude as features to machine learning models  The trouble is that adding lat lon does seem to improve classification  regression  or estimation performance on these limited datasets  Reported metrics go up  errors go down  and everything looks better on paper  So why do I call this a mistake  Because in many cases  the model isn t learning the underlying environmental process at all it s memorizing location  It is learning how to map lat lon to the target This blog post is about why that happens  why it matters  and how we can do better  The discussion draws on two recent GeoHAI Lab papers one on dynamic air quality estimation and another on automated sea ice mapping which together reveal both the failure modes and the productive uses of geolocation in deep learning The illusion of improvement under regional data splitsMost ground truth labeled Earth observation datasets are regional by construction  Air quality monitors cluster around population centers  high quality ice charts  maps  labels  are limited in regional coverage  and generally speaking  labeled data rarely span the full range of environmental and geographic variability we ultimately care about  When such datasets are randomly split into training and test sets  nearby locations frequently appear in both even if timestamps differ  Even under spatial cross validation scenarios where testing sites are geographicallly within and close by training sites  effectively the same thing happens  the danger of memorization In this setting  adding latitude and longitude naïvely almost always improves performance  But this improvement can be deceptive  The model may not be learning better physical relationships at all  it may simply be learning the mapping from latitude and longitude to the outcome  i e   learning where certain outcomes are common This illusion becomes apparent only when evaluation explicitly tests geographic generalization under more extreme spatial blocking and spatial splits for testing  rather than interpolation within familiar regions Evidence from air quality  naïve location breaks under spatial generalizationIn our recent paper  using daily PM2 5 estimation across the continental United States as the application domain  we explicitly evaluated multiple ways of incorporating geolocation into a strong Bi LSTM   attention model that was already generating state of the art results for estimating surface level PM2 5 values  We compared models with no location  raw latitude longitude  sinusoidal encodings  and pretrained Earth embeddings  and evaluated them under both within region  random and spatial dropout of grount truth sitses  and out of region  checkerboard  spatial partitions The checkerboard partitioning scheme is shown below  Entire spatial blocks are held out during training  preventing geographic leakage and forcing true spatial generalization Under random or spatially held out test sites  raw coordinates appeared helpful  But once entire larger regional blocks were withheld  a consistent pattern emerged  naïve latitude longitude and sinusoidal encodings often degraded performance  mostly performing worse than models with no location at all This behavior is summarized in the figure below  which compares test R² and RMSE across geolocation strategies under checkerboard partitions The apparent gains from raw location dissapeared when the model was forced to generalize geographically  suggesting location overfitting rather than transferable learning  The paper goes on to do more analyeses that focus on extreme and larger values during wild fire events  which I don t repeat here A warning from sea ice mapping  feature attribution reveals memorizationWe observed an even more instructive and concerning pattern in our work on automated sea ice mapping from SAR imagery  In that study  we went beyond performance metrics and explicitly analyzed how models used geolocation by applying SHAP based feature attribution across ice classes At first glance  models that incorporated latitude and longitude again appeared to perform better  particularly for difficult and underrepresented ice classes  But SHAP analysis revealed what was actually happening internally For minority ice classes  models that included location features were paying substantially more attention to latitude and longitude than to the SAR observations themselves  In effect  the model was not learning the physical scattering signatures of those ice types  Instead  it was memorizing where those classes tended to occur in the training data  i e   the models were learning a mappint from location to the output class This means the models simply won t generalize  A model that relies on location rather than observation will fail when applied   to a different Arctic region   to the same region under other climate conditions in such a dynamic region   or even to future years as ice regimes shift In a rapidly evolving Arctic  memorizing yesterday s geography is not the same as learning ice observation physics  The SHAP results made this distinction explicit  location was replacing observation  not supporting it Two domains  one common pitfallTaken together  the PM2 5 and sea ice domain results point to the same underlying issue  When training and evaluation data are confined to a region  location becomes a shortcut variable  hurting generalizabiltiy  Models may appear to improve  but the improvement reflects memorization rather than generalizable learning This effect is particularly pronounced for   minority or rare classes   extreme values   and application areas where earth observation signals are ambiguous or noisy In these cases  it is even more likely that geolocation inflates apparent performance while actively undermining   When location does help  treating it as a prior or pretrained embeddingsThe PM2 5 estimation work also analyzed a constructive alternative  The problem is not geolocation itself  but how it is incorporated Instead of concatenating coordinates  we treated pretrained Earth embeddings as priors  conditioning the temporal representation of the model via a Hadamard  element wise  fusion  This design prevents the model from using location as a shortcut  while still allowing geographic context to modulate how dynamic observations are interpreted Conceptually  the model is asking Given what we know about this place  how should today s observations be interpreted This approach did improve performance without lowring the influence of physical observations  and its largest gains appeared in the high concentration tail of PM2 5  where deep learning regression models typically struggle most Even concatenating frozen pretrained earth embeddings helps with performance and generalizability  albeit more experiments are required there to analyze the distribution of different location encoder embeddings and how they influence the outcome  Unfreezing the location encoder is a recipe for disaster though   as it would allow the model to perfectly overfit to locatoins  as expected A design principle for GeoAIThe combined lesson from these two domains is clear   Geolocation should influence interpretation  not replace observation Raw coordinates and naïvely fused embeddings invite memorization under regional splits  Feature attribution methods like SHAP make this failure mode visible  particularly for rare classes and extremes  In contrast  treating location as a prior preserves the dominance of physical signals while improving robustness and generalization As GeoAI models are increasingly deployed beyond their training domains and under accelerating environmental change this distinction becomes foundational rather than optional Further reading      Performance and generalizability impacts of incorporating location encoders into deep learning for dynamic PM2 5 estimationKarimzadeh  M   Wang  Z    amp  Crooks  J  L   2025   GIScience  amp  Remote Sensing https   doi org 10 1080 15481603 2025 2594797        Enhancing and interpreting deep learning for sea ice charting using the AutoICE benchmark Jalayer  S   Alkaee Taleghan  S   Pires de Lima  R   Vahedi  B   Hughes  N   Banaei Kashani  F    amp  Karimzadeh  M   2025   Remote Sensing of Environment  https   doi org 10 1016 j rse 2025 113566  ">
    Most labeled datasets for environmental and geospatial applications, especially those that represent true “ground truth” from field measurements, are collected in fairly limited regions. Whether I am reading research papers or reviewing student proposals in my machine learning and spatial data class, I see one common mistake: adding latitude and longitude as features to machine-learning models. The trouble is that adding lat/lon does seem to improve classification, regression, or estimation performance on these limited datasets. Reported metrics go up, errors go down, and everything looks better on paper. So why do I call this a mistake? Because in many cases, the model isn’t learning the underlying environmental process at all—it’s memorizing location. It is learning how to map lat/lon to the target.

  </p>
  <p data-search="Most labeled datasets for environmental and geospatial applications  especially those that represent true  ground truth  from field measurements  are collected in fairly limited regions  Whether I am reading research papers or reviewing student proposals in my machine learning and spatial data class  I see one common mistake  adding latitude and longitude as features to machine learning models  The trouble is that adding lat lon does seem to improve classification  regression  or estimation performance on these limited datasets  Reported metrics go up  errors go down  and everything looks better on paper  So why do I call this a mistake  Because in many cases  the model isn t learning the underlying environmental process at all it s memorizing location  It is learning how to map lat lon to the target This blog post is about why that happens  why it matters  and how we can do better  The discussion draws on two recent GeoHAI Lab papers one on dynamic air quality estimation and another on automated sea ice mapping which together reveal both the failure modes and the productive uses of geolocation in deep learning The illusion of improvement under regional data splitsMost ground truth labeled Earth observation datasets are regional by construction  Air quality monitors cluster around population centers  high quality ice charts  maps  labels  are limited in regional coverage  and generally speaking  labeled data rarely span the full range of environmental and geographic variability we ultimately care about  When such datasets are randomly split into training and test sets  nearby locations frequently appear in both even if timestamps differ  Even under spatial cross validation scenarios where testing sites are geographicallly within and close by training sites  effectively the same thing happens  the danger of memorization In this setting  adding latitude and longitude naïvely almost always improves performance  But this improvement can be deceptive  The model may not be learning better physical relationships at all  it may simply be learning the mapping from latitude and longitude to the outcome  i e   learning where certain outcomes are common This illusion becomes apparent only when evaluation explicitly tests geographic generalization under more extreme spatial blocking and spatial splits for testing  rather than interpolation within familiar regions Evidence from air quality  naïve location breaks under spatial generalizationIn our recent paper  using daily PM2 5 estimation across the continental United States as the application domain  we explicitly evaluated multiple ways of incorporating geolocation into a strong Bi LSTM   attention model that was already generating state of the art results for estimating surface level PM2 5 values  We compared models with no location  raw latitude longitude  sinusoidal encodings  and pretrained Earth embeddings  and evaluated them under both within region  random and spatial dropout of grount truth sitses  and out of region  checkerboard  spatial partitions The checkerboard partitioning scheme is shown below  Entire spatial blocks are held out during training  preventing geographic leakage and forcing true spatial generalization Under random or spatially held out test sites  raw coordinates appeared helpful  But once entire larger regional blocks were withheld  a consistent pattern emerged  naïve latitude longitude and sinusoidal encodings often degraded performance  mostly performing worse than models with no location at all This behavior is summarized in the figure below  which compares test R² and RMSE across geolocation strategies under checkerboard partitions The apparent gains from raw location dissapeared when the model was forced to generalize geographically  suggesting location overfitting rather than transferable learning  The paper goes on to do more analyeses that focus on extreme and larger values during wild fire events  which I don t repeat here A warning from sea ice mapping  feature attribution reveals memorizationWe observed an even more instructive and concerning pattern in our work on automated sea ice mapping from SAR imagery  In that study  we went beyond performance metrics and explicitly analyzed how models used geolocation by applying SHAP based feature attribution across ice classes At first glance  models that incorporated latitude and longitude again appeared to perform better  particularly for difficult and underrepresented ice classes  But SHAP analysis revealed what was actually happening internally For minority ice classes  models that included location features were paying substantially more attention to latitude and longitude than to the SAR observations themselves  In effect  the model was not learning the physical scattering signatures of those ice types  Instead  it was memorizing where those classes tended to occur in the training data  i e   the models were learning a mappint from location to the output class This means the models simply won t generalize  A model that relies on location rather than observation will fail when applied   to a different Arctic region   to the same region under other climate conditions in such a dynamic region   or even to future years as ice regimes shift In a rapidly evolving Arctic  memorizing yesterday s geography is not the same as learning ice observation physics  The SHAP results made this distinction explicit  location was replacing observation  not supporting it Two domains  one common pitfallTaken together  the PM2 5 and sea ice domain results point to the same underlying issue  When training and evaluation data are confined to a region  location becomes a shortcut variable  hurting generalizabiltiy  Models may appear to improve  but the improvement reflects memorization rather than generalizable learning This effect is particularly pronounced for   minority or rare classes   extreme values   and application areas where earth observation signals are ambiguous or noisy In these cases  it is even more likely that geolocation inflates apparent performance while actively undermining   When location does help  treating it as a prior or pretrained embeddingsThe PM2 5 estimation work also analyzed a constructive alternative  The problem is not geolocation itself  but how it is incorporated Instead of concatenating coordinates  we treated pretrained Earth embeddings as priors  conditioning the temporal representation of the model via a Hadamard  element wise  fusion  This design prevents the model from using location as a shortcut  while still allowing geographic context to modulate how dynamic observations are interpreted Conceptually  the model is asking Given what we know about this place  how should today s observations be interpreted This approach did improve performance without lowring the influence of physical observations  and its largest gains appeared in the high concentration tail of PM2 5  where deep learning regression models typically struggle most Even concatenating frozen pretrained earth embeddings helps with performance and generalizability  albeit more experiments are required there to analyze the distribution of different location encoder embeddings and how they influence the outcome  Unfreezing the location encoder is a recipe for disaster though   as it would allow the model to perfectly overfit to locatoins  as expected A design principle for GeoAIThe combined lesson from these two domains is clear   Geolocation should influence interpretation  not replace observation Raw coordinates and naïvely fused embeddings invite memorization under regional splits  Feature attribution methods like SHAP make this failure mode visible  particularly for rare classes and extremes  In contrast  treating location as a prior preserves the dominance of physical signals while improving robustness and generalization As GeoAI models are increasingly deployed beyond their training domains and under accelerating environmental change this distinction becomes foundational rather than optional Further reading      Performance and generalizability impacts of incorporating location encoders into deep learning for dynamic PM2 5 estimationKarimzadeh  M   Wang  Z    amp  Crooks  J  L   2025   GIScience  amp  Remote Sensing https   doi org 10 1080 15481603 2025 2594797        Enhancing and interpreting deep learning for sea ice charting using the AutoICE benchmark Jalayer  S   Alkaee Taleghan  S   Pires de Lima  R   Vahedi  B   Hughes  N   Banaei Kashani  F    amp  Karimzadeh  M   2025   Remote Sensing of Environment  https   doi org 10 1016 j rse 2025 113566  " class="project-excerpt-content">
    Most labeled datasets for environmental and geospatial applications, especially those that represent true “ground truth” from field measurements, are collected in fairly limited regions. Whether I am reading research papers or reviewing student proposals in my machine learning and spatial data class, I see one common mistake: adding latitude and...
    <a href="/2026/02/08/geolocation-for-deep-learning.html" class="read-more">Continue reading.</a>
  </p>  
</div>

<h3 id="2025">2025</h3>

<div class="post-excerpt">
  
  
  <a href="/2025/12/20/earth-embedding-air-pollution.html">Locatoin Encoder Earth Embeddings as Priors for Dynamic Air Quality Estimation</a>

  <div class="post-info">
  
    
    
      

<div class="portrait-wrapper">
  <a href="/members/morteza-karimzadeh.html" class="portrait" data-style="tiny" aria-label="Morteza Karimzadeh">
    <img src="/images/member-images/morteza-karimzadeh.jpg" class="portrait-image" alt="member portrait" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">

    
      <span class="portrait-text">
        
          <span class="portrait-name">
            Morteza Karimzadeh
          </span>
        

        
          <span class="portrait-role">
            
            <i class="icon fa-solid fa-microscope"></i>
            <span>Director</span>
          </span>
        
      </span>
    
  </a>
</div>

    
  

  
  

  
    <span data-tooltip="Originally published on">
      <i class="icon fa-regular fa-calendar"></i>
      <span>December 20, 2025</span>
    </span>
  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>February 10, 2026</span>
    </span>
  
</div>


  


  <div class="tags" data-link="/blog">
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('spatiotemporal')" data-tooltip='Show items with the tag "spatiotemporal"'>
        spatiotemporal
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('machine learning')" data-tooltip='Show items with the tag "machine learning"'>
        machine learning
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('remote sensing')" data-tooltip='Show items with the tag "remote sensing"'>
        remote sensing
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('public health')" data-tooltip='Show items with the tag "public health"'>
        public health
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('air pollution')" data-tooltip='Show items with the tag "air pollution"'>
        air pollution
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('foundation model')" data-tooltip='Show items with the tag "foundation model"'>
        foundation model
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('earth embeddings')" data-tooltip='Show items with the tag "earth embeddings"'>
        earth embeddings
      </a>
    
  </div>





  
  
  <p data-search="There has been considerable excitement  along with reasonable amounts of skepticism  around geospatial foundation models and so called Earth embeddings  These models promise reusable representations of places learned from large  heterogeneous datasets  and they are increasingly treated as a general purpose building block for downstream geospatial machine learning tasks  Yet one question kept resurfacing  what actually happens when static Earth embeddings are used in a higly dynamic estimation problem In our paper published in GIScience  amp  Remote Sensing  we explored this question through the lens of daily surface level PM2 5 estimation across the continental United States  This is a particularly demanding setting  Atmospheric transport  wildfire smoke  and weather systems can change rapidly from day to day  and deep learning based regression models often struggle not at the mean of the distribution but at its extremes precisely where errors matter most for public health and policy  i e   highly polluted days At the core of the problem is a familiar but difficult inference task  Satellites observe aerosols as vertical column measurements  yet the quantity of interest for exposure and health studies is the near surface concentration of PM2 5  often in locations far from ground monitors  where we live and breathe    Even with rich Earth observations such as aerosol optical depth  AOD   meteorology  and smoke indicators  learning this mapping remains challenging  Deep learning models frequently achieve strong average performance while systematically underestimating or smoothing away the high concentration tail of the distribution Most Earth embeddings proposed to date have been evaluated on relatively static or temporally smoothed targets  including long term air temperature  biomass  land cover  or species distributions  These benchmarks are valuable  but they do not fully probe how static representations behave when embedded in a dynamic  nonlinear estimation problem where rare extremes make up the bulk of error  This gap motivated us to ask whether Earth embeddings can help in settings where temporal variability drives the signal A key conceptual insight from our experiments is that Earth embeddings are most effective when treated as priors rather than as additional features  Instead of concatenating embeddings to the input and allowing the model to memorize location specific relationships  we conditioned a strong Bi LSTM with attention on pretrained  frozen Earth embeddings using a simple Hadamard  element wise  fusion  Framed differently  the model is encouraged to ask  given what we know about this place  how should today s observations be interpreted  This conditioning mechanism allows static geographic context to modulate the interpretation of dynamic satellite and meteorological signals The architecture used in our experiments is shown below  illustrating how the Earth embedding interacts multiplicatively with the temporal representation learned from Earth observations One of the more surprising results was that this prior conditioning strategy improved performance even during highly dynamic events  including wildfire smoke episodes  In particular  we observed consistent gains at the high concentration tail of the PM2 5 distribution  where deep learning regression models typically degrade despite access to rich inputs such as AOD and meteorology  Seeing improvements in extreme value behavior rather than just marginal gains in average error was both unexpected and encouraging The figure below illustrates an example from the Dixie Fire  where conditioning on GeoCLIP Earth embeddings leads to markedly better recovery of high PM2 5 concentrations compared to an otherwise identical model without such conditioning Another notable finding emerged from comparing different sources of Earth embeddings  In the context of air pollution estimation  ground level imagery based embeddings  GeoCLIP  consistently outperformed satellite imagery based embeddings  SatCLIP   This likely reflects the kinds of signals PM2 5 estimation depends on  including built environment characteristics  infrastructure  and proxies for human activity  which are often more directly captured by ground level imagery  At the same time  this result highlights an important open question for the field  we need more controlled comparisons of Earth embeddings that differ only in imagery source  rather than also differing in positional encoding  embedding dimensionality  or training objective To ground these conceptual insights empirically  we systematically evaluated four geolocation strategies within a unified Bi LSTM   attention framework  no geolocation  raw latitude longitude  sinusoidal latitude longitude  and pretrained Earth embeddings  Across both within region and out of region spatial evaluation schemes  a consistent pattern emerged  Naive coordinate encodings can improve interpolation but often harm generalization  whereas Earth embeddings particularly when fused via Hadamard product improve both accuracy and geographic transferability  These results reinforce the interpretation of Hadamard fusion as a mechanism for conditioning dynamic Earth observation models on geographic priors  rather than simply adding more predictors Taken together  these findings suggest a broader takeaway  Earth embedding foundation models are more than representations of place  When used appropriately  they act as a mechanism for injecting geographic prior knowledge into dynamic inference  stabilizing predictions and improving performance in rare but large extremes  This perspective matter in how Earth embeddings might be used in environmental machine learning  especially for applications where extremes matter more than averages The full paper  Performance and generalizability impacts of incorporating location encoders into deep learning for dynamic PM2 5 estimation  is available in GIScience  amp  Remote Sensing  Karimzadeh  Wang   amp  Crooks  2025  https   doi org 10 1080 15481603 2025 2594797Code to reproduce the experiments is available at https   github com geohai PM2 5 CONUS LSTMThis work was made possible by a close collaboration with Zhongying Wang  our outstanding doctoral student who led much of the modeling effort  and James Crooks  whose expertise in health relevant exposure modeling motivated the work  but also whose intimate knowledge of PM2 5 formation and EPA sensing helped us set up the modeling pipline and the framing of PM2 5 estimation throughout the study ">
    There has been considerable excitement, along with reasonable amounts of skepticism, around geospatial foundation models and so-called Earth embeddings. These models promise reusable representations of places learned from large, heterogeneous datasets, and they are increasingly treated as a general-purpose building block for downstream geospatial machine learning tasks. Yet one question kept resurfacing: what actually happens when static Earth embeddings are used in a higly dynamic estimation problem?

  </p>
  <p data-search="There has been considerable excitement  along with reasonable amounts of skepticism  around geospatial foundation models and so called Earth embeddings  These models promise reusable representations of places learned from large  heterogeneous datasets  and they are increasingly treated as a general purpose building block for downstream geospatial machine learning tasks  Yet one question kept resurfacing  what actually happens when static Earth embeddings are used in a higly dynamic estimation problem In our paper published in GIScience  amp  Remote Sensing  we explored this question through the lens of daily surface level PM2 5 estimation across the continental United States  This is a particularly demanding setting  Atmospheric transport  wildfire smoke  and weather systems can change rapidly from day to day  and deep learning based regression models often struggle not at the mean of the distribution but at its extremes precisely where errors matter most for public health and policy  i e   highly polluted days At the core of the problem is a familiar but difficult inference task  Satellites observe aerosols as vertical column measurements  yet the quantity of interest for exposure and health studies is the near surface concentration of PM2 5  often in locations far from ground monitors  where we live and breathe    Even with rich Earth observations such as aerosol optical depth  AOD   meteorology  and smoke indicators  learning this mapping remains challenging  Deep learning models frequently achieve strong average performance while systematically underestimating or smoothing away the high concentration tail of the distribution Most Earth embeddings proposed to date have been evaluated on relatively static or temporally smoothed targets  including long term air temperature  biomass  land cover  or species distributions  These benchmarks are valuable  but they do not fully probe how static representations behave when embedded in a dynamic  nonlinear estimation problem where rare extremes make up the bulk of error  This gap motivated us to ask whether Earth embeddings can help in settings where temporal variability drives the signal A key conceptual insight from our experiments is that Earth embeddings are most effective when treated as priors rather than as additional features  Instead of concatenating embeddings to the input and allowing the model to memorize location specific relationships  we conditioned a strong Bi LSTM with attention on pretrained  frozen Earth embeddings using a simple Hadamard  element wise  fusion  Framed differently  the model is encouraged to ask  given what we know about this place  how should today s observations be interpreted  This conditioning mechanism allows static geographic context to modulate the interpretation of dynamic satellite and meteorological signals The architecture used in our experiments is shown below  illustrating how the Earth embedding interacts multiplicatively with the temporal representation learned from Earth observations One of the more surprising results was that this prior conditioning strategy improved performance even during highly dynamic events  including wildfire smoke episodes  In particular  we observed consistent gains at the high concentration tail of the PM2 5 distribution  where deep learning regression models typically degrade despite access to rich inputs such as AOD and meteorology  Seeing improvements in extreme value behavior rather than just marginal gains in average error was both unexpected and encouraging The figure below illustrates an example from the Dixie Fire  where conditioning on GeoCLIP Earth embeddings leads to markedly better recovery of high PM2 5 concentrations compared to an otherwise identical model without such conditioning Another notable finding emerged from comparing different sources of Earth embeddings  In the context of air pollution estimation  ground level imagery based embeddings  GeoCLIP  consistently outperformed satellite imagery based embeddings  SatCLIP   This likely reflects the kinds of signals PM2 5 estimation depends on  including built environment characteristics  infrastructure  and proxies for human activity  which are often more directly captured by ground level imagery  At the same time  this result highlights an important open question for the field  we need more controlled comparisons of Earth embeddings that differ only in imagery source  rather than also differing in positional encoding  embedding dimensionality  or training objective To ground these conceptual insights empirically  we systematically evaluated four geolocation strategies within a unified Bi LSTM   attention framework  no geolocation  raw latitude longitude  sinusoidal latitude longitude  and pretrained Earth embeddings  Across both within region and out of region spatial evaluation schemes  a consistent pattern emerged  Naive coordinate encodings can improve interpolation but often harm generalization  whereas Earth embeddings particularly when fused via Hadamard product improve both accuracy and geographic transferability  These results reinforce the interpretation of Hadamard fusion as a mechanism for conditioning dynamic Earth observation models on geographic priors  rather than simply adding more predictors Taken together  these findings suggest a broader takeaway  Earth embedding foundation models are more than representations of place  When used appropriately  they act as a mechanism for injecting geographic prior knowledge into dynamic inference  stabilizing predictions and improving performance in rare but large extremes  This perspective matter in how Earth embeddings might be used in environmental machine learning  especially for applications where extremes matter more than averages The full paper  Performance and generalizability impacts of incorporating location encoders into deep learning for dynamic PM2 5 estimation  is available in GIScience  amp  Remote Sensing  Karimzadeh  Wang   amp  Crooks  2025  https   doi org 10 1080 15481603 2025 2594797Code to reproduce the experiments is available at https   github com geohai PM2 5 CONUS LSTMThis work was made possible by a close collaboration with Zhongying Wang  our outstanding doctoral student who led much of the modeling effort  and James Crooks  whose expertise in health relevant exposure modeling motivated the work  but also whose intimate knowledge of PM2 5 formation and EPA sensing helped us set up the modeling pipline and the framing of PM2 5 estimation throughout the study " class="project-excerpt-content">
    There has been considerable excitement, along with reasonable amounts of skepticism, around geospatial foundation models and so-called Earth embeddings. These models promise reusable representations of places learned from large, heterogeneous datasets, and they are increasingly treated as a general-purpose building block for downstream geospatial machine learning tasks. Yet one question...
    <a href="/2025/12/20/earth-embedding-air-pollution.html" class="read-more">Continue reading.</a>
  </p>  
</div>

<h3 id="2022">2022</h3>

<div class="post-excerpt">
  
  
  <a href="/2022/06/01/social-media-for-covid-forecast.html">Forecasting the Geographic Incidence of COVID-19 How Does Social Media Help?</a>

  <div class="post-info">
  
    
    
      

<div class="portrait-wrapper">
  <a href="/members/morteza-karimzadeh.html" class="portrait" data-style="tiny" aria-label="Morteza Karimzadeh">
    <img src="/images/member-images/morteza-karimzadeh.jpg" class="portrait-image" alt="member portrait" loading="lazy" onerror="this.src = '/images/fallback.svg'; this.onerror = null;">

    
      <span class="portrait-text">
        
          <span class="portrait-name">
            Morteza Karimzadeh
          </span>
        

        
          <span class="portrait-role">
            
            <i class="icon fa-solid fa-microscope"></i>
            <span>Director</span>
          </span>
        
      </span>
    
  </a>
</div>

    
  

  
  

  
    <span data-tooltip="Originally published on">
      <i class="icon fa-regular fa-calendar"></i>
      <span>June 01, 2022</span>
    </span>
  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>February 10, 2026</span>
    </span>
  
</div>


  


  <div class="tags" data-link="/blog">
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('spatiotemporal')" data-tooltip='Show items with the tag "spatiotemporal"'>
        spatiotemporal
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('machine learning')" data-tooltip='Show items with the tag "machine learning"'>
        machine learning
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('COVID-19')" data-tooltip='Show items with the tag "COVID-19"'>
        COVID-19
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('public health')" data-tooltip='Show items with the tag "public health"'>
        public health
      </a>
    
      <a href="javascript:void(0);" class="tag" onclick="toggleTag('epidemiology')" data-tooltip='Show items with the tag "epidemiology"'>
        epidemiology
      </a>
    
  </div>





  
  
  <p data-search="Forecasting COVID 19 geographic spread is a challenging task  Reliable forecasting is crucial  as it is used in resource allocation and allows local authorities and health officials to implement timely interventions In these studies  we show that AI based short term forecasting of COVID 19 can outperform conventional compartmental models that have been long used in epidemiological modeling  These traditional models  to a large extent  failed to reliably predict the local surges in the US  This was partially responsible for the reactive planning of local governments only after a local surge was underway   Deep learning is data driven  and successfully models the variations within US counties  from population demographics  to masking and social distancing adherence   to varying levels of immunity due to vaccination or waning immunity over time  Additionally  in our work  we show that social media connectedness can be successfully used to model the spatial diffusion of the disease  In other words  we used data created from social media friendship networks to estimate the amount of transmission from one area to another  Specifically  we used Metas   Facebook s  Social Connectedness Index  an index that quantifies the proportion of users in county pairs  or state pairs  that are friends on Facebook  Building on this dataset  our deep learning models incorporate the rate of between county and between state transmission of COVID 19  and thus  improve the forecasts Our  Nature Com  study also found that Social Media Connectedness is usually a better measure for quantifying human interactions compared to cell phone driven movement data  which passively monitors the number of cell phones  and thus  people carrying them  that move from one area to another  We hypothesize that the predictive power of social media data over cell phone movement data for quantifying disease transmission may say something about human behavior  people may mask up and social distance when they go to work or shop  but may not adhere to social distancing or masking when spending time with friends  However  this is only a hypothesis and needs more investigation  Our goal is forecasting for all counties  and we can only look at the predictive power of variables  but not make an inference about their precise significance  In short  social media data is a good metric for measuring the amount of human interaction  and this dataset is available for more than 35 countries  even in data poor regions of the world  where cell phone mobility datasets are not readily available  Additionally  many US cell phone companies shut down their  free  publication of movement data early in 2021 after vaccines emerged Building on our findings  we have been contributing to national forecasting efforts  Every week  teams around the country  including us  representing CU Boulder   use the latest data and generate short term forecasts and contribute to the central repository of the US COVID 19 Forecast Hub  The Hub  generates an ensemble of all these forecasts  which the CDC then uses in reporting  communications and publications  As the cases of COVID 19 decline  we are all wary of new variants and these forecasting efforts will continue  There is new emphasis on hospitalization forecasts as a better metric for the impact of the virus  and thus  we will continue to contribute daily hospitalization forecasts to the Hub as well ">
    Forecasting COVID-19 geographic spread is a challenging task. Reliable forecasting is crucial, as it is used in resource allocation and allows local authorities and health officials to implement timely interventions.

  </p>
  <p data-search="Forecasting COVID 19 geographic spread is a challenging task  Reliable forecasting is crucial  as it is used in resource allocation and allows local authorities and health officials to implement timely interventions In these studies  we show that AI based short term forecasting of COVID 19 can outperform conventional compartmental models that have been long used in epidemiological modeling  These traditional models  to a large extent  failed to reliably predict the local surges in the US  This was partially responsible for the reactive planning of local governments only after a local surge was underway   Deep learning is data driven  and successfully models the variations within US counties  from population demographics  to masking and social distancing adherence   to varying levels of immunity due to vaccination or waning immunity over time  Additionally  in our work  we show that social media connectedness can be successfully used to model the spatial diffusion of the disease  In other words  we used data created from social media friendship networks to estimate the amount of transmission from one area to another  Specifically  we used Metas   Facebook s  Social Connectedness Index  an index that quantifies the proportion of users in county pairs  or state pairs  that are friends on Facebook  Building on this dataset  our deep learning models incorporate the rate of between county and between state transmission of COVID 19  and thus  improve the forecasts Our  Nature Com  study also found that Social Media Connectedness is usually a better measure for quantifying human interactions compared to cell phone driven movement data  which passively monitors the number of cell phones  and thus  people carrying them  that move from one area to another  We hypothesize that the predictive power of social media data over cell phone movement data for quantifying disease transmission may say something about human behavior  people may mask up and social distance when they go to work or shop  but may not adhere to social distancing or masking when spending time with friends  However  this is only a hypothesis and needs more investigation  Our goal is forecasting for all counties  and we can only look at the predictive power of variables  but not make an inference about their precise significance  In short  social media data is a good metric for measuring the amount of human interaction  and this dataset is available for more than 35 countries  even in data poor regions of the world  where cell phone mobility datasets are not readily available  Additionally  many US cell phone companies shut down their  free  publication of movement data early in 2021 after vaccines emerged Building on our findings  we have been contributing to national forecasting efforts  Every week  teams around the country  including us  representing CU Boulder   use the latest data and generate short term forecasts and contribute to the central repository of the US COVID 19 Forecast Hub  The Hub  generates an ensemble of all these forecasts  which the CDC then uses in reporting  communications and publications  As the cases of COVID 19 decline  we are all wary of new variants and these forecasting efforts will continue  There is new emphasis on hospitalization forecasts as a better metric for the impact of the virus  and thus  we will continue to contribute daily hospitalization forecasts to the Hub as well " class="project-excerpt-content">
    Forecasting COVID-19 geographic spread is a challenging task. Reliable forecasting is crucial, as it is used in resource allocation and allows local authorities and health officials to implement timely interventions.

    <a href="/2022/06/01/social-media-for-covid-forecast.html" class="read-more">Continue reading.</a>
  </p>  
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/images/background.jpg')" data-dark="true" data-size="wide">

<div style="display: flex; flex-wrap: wrap; justify-content: space-between; align-items: center; max-width: 100%; margin: 0 auto; padding: 0 0px;">
  <div style="flex: 1; text-align: left; min-width: 300px; padding-right: 20px;">
    <a href="/contact">Contact Us</a>
  </div>
  <div style="flex: 1; text-align: right; min-width: 300px; white-space: nowrap; padding-top: 0px;">
    © 2026 GeoHAI
      |   Source forked from 
    <a href="https://github.com/greenelab/lab-website-template" target="_blank">LWT</a>
  </div>
</div>

  <!-- removing the links for now. -->
  <!-- <div>
    
      
      
      



  <div class="button-wrapper">
    <a
      class="button"
      href=""
      
        data-tooltip="Email"
      
      data-style="bare"
      
      aria-label="Email"
    >
      <i class="icon fa-solid fa-envelope"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a
      class="button"
      href="https://orcid.org/0000-0002-6498-1763"
      
        data-tooltip="ORCID"
      
      data-style="bare"
      
      aria-label="ORCID"
    >
      <i class="icon fa-brands fa-orcid"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a
      class="button"
      href="https://scholar.google.com/citations?user=Vy2oR2kAAAAJ&sortby=pubdate"
      
        data-tooltip="Google Scholar"
      
      data-style="bare"
      
      aria-label="Google Scholar"
    >
      <i class="icon fa-brands fa-google"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a
      class="button"
      href="https://github.com/geohai"
      
        data-tooltip="GitHub"
      
      data-style="bare"
      
      aria-label="GitHub"
    >
      <i class="icon fa-brands fa-github"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a
      class="button"
      href="https://twitter.com/geohai_lab"
      
        data-tooltip="Twitter"
      
      data-style="bare"
      
      aria-label="Twitter"
    >
      <i class="icon fa-brands fa-twitter"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a
      class="button"
      href="https://youtube.com/geohai_lab"
      
        data-tooltip="YouTube"
      
      data-style="bare"
      
      aria-label="YouTube"
    >
      <i class="icon fa-brands fa-youtube"></i>
      
    </a>
  </div>


    
  </div> -->

  <!-- moved to the contact page -->
  <!-- <div>
    &copy; 2026
    GeoHAI
    &nbsp; | &nbsp; Built with
    <a href="https://github.com/greenelab/lab-website-template">
      Lab Website Template
    </a>
  </div> -->

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
