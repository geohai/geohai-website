<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="/preview/pr-48/feed.xml" rel="self" type="application/atom+xml" /><link href="/preview/pr-48/" rel="alternate" type="text/html" /><updated>2026-02-10T01:34:14+00:00</updated><id>/preview/pr-48/feed.xml</id><title type="html">GeoHAI</title><subtitle>Advancing geospatial use-inspired research at the intersection of AI and human-centered design</subtitle><entry><title type="html">Rethinking Geolocation Features in Deep Learning and Geospatial Applications</title><link href="/preview/pr-48/2026/02/08/geolocation-for-deep-learning.html" rel="alternate" type="text/html" title="Rethinking Geolocation Features in Deep Learning and Geospatial Applications" /><published>2026-02-08T00:00:00+00:00</published><updated>2026-02-10T01:33:56+00:00</updated><id>/preview/pr-48/2026/02/08/geolocation-for-deep-learning</id><content type="html" xml:base="/preview/pr-48/2026/02/08/geolocation-for-deep-learning.html"><![CDATA[<p>Most labeled datasets for environmental and geospatial applications, especially those that represent true “ground truth” from field measurements, are collected in fairly limited regions. Whether I am reading research papers or reviewing student proposals in my <strong>machine learning and spatial data</strong> class, I see one common mistake: adding latitude and longitude as features to machine-learning models. The trouble is that adding lat/lon does seem to improve classification, regression, or estimation performance on these limited datasets. Reported metrics go up, errors go down, and everything looks better on paper. So why do I call this a mistake? Because in many cases, the model isn’t learning the underlying environmental process at all—it’s memorizing location. It is learning how to map lat/lon to the target.</p>

<!-- This is a comment, add reference to deep learning for reconstructiong low frequency features, esther's paper on pretarined overfitting  -->

<p>This blog post is about why that happens, why it matters, and how we can do better. The discussion draws on two recent GeoHAI Lab papers—one on <strong>dynamic air-quality estimation</strong> and another on <strong>automated sea-ice mapping</strong>—which together reveal both the <em>failure modes</em> and the <em>productive uses</em> of geolocation in deep learning.</p>

<hr />

<h3 id="the-illusion-of-improvement-under-regional-data-splits">The illusion of improvement under regional data splits</h3>

<p>Most ground-truth labeled Earth-observation datasets are <strong>regional by construction</strong>. Air-quality monitors cluster around population centers, high-quality ice charts (maps, labels) are limited in regional coverage, and generally-speaking, labeled data rarely span the full range of environmental and geographic variability we ultimately care about. When such datasets are randomly split into training and test sets, nearby locations frequently appear in both—even if timestamps differ. Even under spatial cross-validation scenarios where testing sites are geographicallly within and close-by training sites, effectively the same thing happens: the danger of memorization.</p>

<p>In this setting, adding latitude and longitude naïvely almost always improves performance. But this improvement can be deceptive. The model may not be learning better physical relationships at all, it may simply be learning the mapping from latitude and longitude to the outcome, i.e., learning <em>where</em> certain outcomes are common.</p>

<p>This illusion becomes apparent only when evaluation explicitly tests <strong>geographic generalization</strong> under more extreme spatial blocking and spatial splits for testing, rather than interpolation within familiar regions.</p>

<hr />

<h3 id="evidence-from-air-quality-naïve-location-breaks-under-spatial-generalization">Evidence from air quality: naïve location breaks under spatial generalization</h3>

<p>In our recent paper, using <strong>daily PM2.5 estimation across the continental United States</strong> as the application domain, we explicitly evaluated multiple ways of incorporating geolocation into a strong Bi-LSTM + attention model that was already generating state-of-the-art results for estimating surface-level PM2.5 values. We compared models with no location, raw latitude/longitude, sinusoidal encodings, and pretrained Earth embeddings, and evaluated them under both within-region (random and spatial dropout of grount truth sitses) and out-of-region (checkerboard) spatial partitions.</p>

<p>The checkerboard partitioning scheme is shown below. Entire spatial blocks are held out during training, preventing geographic leakage and forcing true spatial generalization:</p>

<p><img src="https://res.cloudinary.com/dz3zgmhnr/image/upload/v1770569126/cb_deg8.0_partition_hitjvl.png" alt="Checkerboard spatial partitions used for evaluation" /></p>

<p>Under random or spatially held-out test sites, raw coordinates appeared helpful. But once entire larger regional blocks were withheld, a consistent pattern emerged: <strong>naïve latitude/longitude and sinusoidal encodings often degraded performance</strong>, mostly performing worse than models with no location at all.</p>

<p>This behavior is summarized in the figure below, which compares test R² and RMSE across geolocation strategies under checkerboard partitions:</p>

<p><img src="https://res.cloudinary.com/dz3zgmhnr/image/upload/v1770569164/metrics_checkerboard_deg8_jd9lde.png" alt="Performance comparison across geolocation strategies" /></p>

<p>The apparent gains from raw location dissapeared when the model was forced to generalize geographically, suggesting <strong>location overfitting</strong> rather than transferable learning. The paper goes on to do more analyeses that focus on extreme and larger values during wild-fire events, which I don’t repeat here.</p>

<hr />

<h3 id="a-warning-from-sea-ice-mapping-feature-attribution-reveals-memorization">A warning from sea ice mapping: feature attribution reveals memorization</h3>

<p>We observed an even more instructive and concerning pattern in our work on <strong>automated sea-ice mapping from SAR imagery</strong>. In that study, we went beyond performance metrics and explicitly analyzed <em>how</em> models used geolocation by applying <strong>SHAP-based feature attribution</strong> across ice classes.</p>

<p>At first glance, models that incorporated latitude and longitude again appeared to perform better, particularly for difficult and underrepresented ice classes. But SHAP analysis revealed what was actually happening internally.</p>

<p>For <strong>minority ice classes</strong>, models that included location features were <strong>paying substantially more attention to latitude and longitude than to the SAR observations themselves</strong>. In effect, the model was not learning the physical scattering signatures of those ice types. Instead, it was memorizing <em>where</em> those classes tended to occur in the training data, i.e., the models were learning a mappint from location to the output class.</p>

<p>This means the models simply won’t generalize. A model that relies on location rather than observation will fail when applied:</p>

<ul>
  <li>to a different Arctic region,</li>
  <li>to the same region under other climate conditions in such a dynamic region,</li>
  <li>or even to future years as ice regimes shift.</li>
</ul>

<p>In a rapidly evolving Arctic, memorizing yesterday’s geography is not the same as learning ice observation physics. The SHAP results made this distinction explicit: <strong>location was replacing observation, not supporting it</strong>.</p>

<hr />

<h3 id="two-domains-one-common-pitfall">Two domains, one common pitfall</h3>

<p>Taken together, the PM2.5 and sea-ice domain results point to the same underlying issue. When training and evaluation data are confined to a region, <strong>location becomes a shortcut variable</strong>, hurting generalizabiltiy. Models may appear to improve, but the improvement reflects memorization rather than generalizable learning.</p>

<p>This effect is particularly pronounced for:</p>

<ul>
  <li>minority or rare classes,</li>
  <li>extreme values,</li>
  <li>and application areas where earth observation signals are ambiguous or noisy.</li>
</ul>

<p>In these cases, it is even more likely that geolocation inflates apparent performance while actively undermining  .</p>

<hr />

<h3 id="when-location-does-help-treating-it-as-a-prior-or-pretrained-embeddings">When location <em>does</em> help: treating it as a prior or pretrained embeddings</h3>

<p>The PM2.5 estimation work also analyzed a constructive alternative. The problem is not geolocation itself, but <strong>how it is incorporated</strong>.</p>

<p>Instead of concatenating coordinates, we treated <strong>pretrained Earth embeddings as priors</strong>, conditioning the temporal representation of the model via a Hadamard (element-wise) fusion. This design prevents the model from using location as a shortcut, while still allowing geographic context to modulate how dynamic observations are interpreted.</p>

<p>Conceptually, the model is asking:</p>

<p><em>Given what we know about this place, how should today’s observations be interpreted?</em></p>

<p>This approach did improve performance <strong>without lowring the influence of physical observations</strong>, and its largest gains appeared in the <strong>high-concentration tail of PM2.5</strong>, where deep-learning regression models typically struggle most.</p>

<p>Even concatenating frozen pretrained earth embeddings helps with performance and generalizability, albeit more experiments are required there to analyze the distribution of different location encoder embeddings and how they influence the outcome. Unfreezing the location encoder is a recipe for disaster though,  as it would allow the model to perfectly overfit to locatoins, as expected.</p>

<hr />

<h3 id="a-design-principle-for-geoai">A design principle for GeoAI</h3>

<p>The combined lesson from these two domains is clear:</p>

<blockquote>
  <p><strong>Geolocation should influence interpretation, not replace observation.</strong></p>
</blockquote>

<p>Raw coordinates and naïvely fused embeddings invite memorization under regional splits. Feature-attribution methods like SHAP make this failure mode visible, particularly for rare classes and extremes. In contrast, treating location as a <em>prior</em> preserves the dominance of physical signals while improving robustness and generalization.</p>

<p>As GeoAI models are increasingly deployed beyond their training domains—and under accelerating environmental change—this distinction becomes foundational rather than optional.</p>

<hr />

<h3 id="further-reading">Further reading</h3>

<ul>
  <li>
    <p><strong>Performance and generalizability impacts of incorporating location encoders into deep learning for dynamic PM2.5 estimation</strong>
Karimzadeh, M., Wang, Z., &amp; Crooks, J. L. (2025). <em>GIScience &amp; Remote Sensing</em>.
<a href="https://doi.org/10.1080/15481603.2025.2594797">https://doi.org/10.1080/15481603.2025.2594797</a></p>
  </li>
  <li>
    <p><strong>Enhancing and interpreting deep learning for sea ice charting using the AutoICE benchmark</strong>
 Jalayer, S., Alkaee Taleghan, S., Pires de Lima, R., Vahedi, B., Hughes, N., Banaei-Kashani, F., &amp; Karimzadeh, M. (2025). <em>Remote Sensing of Environment</em>.
 <a href="https://doi.org/10.1016/j.rse.2025.113566">https://doi.org/10.1016/j.rse.2025.113566</a></p>
  </li>
</ul>]]></content><author><name>morteza-karimzadeh</name></author><category term="spatiotemporal" /><category term="machine learning" /><category term="remote sensing" /><category term="air pollution" /><category term="sea ice" /><category term="foundation model" /><category term="earth embeddings" /><summary type="html"><![CDATA[Most labeled datasets for environmental and geospatial applications, especially those that represent true “ground truth” from field measurements, are collected in fairly limited regions. Whether I am reading research papers or reviewing student proposals in my machine learning and spatial data class, I see one common mistake: adding latitude and longitude as features to machine-learning models. The trouble is that adding lat/lon does seem to improve classification, regression, or estimation performance on these limited datasets. Reported metrics go up, errors go down, and everything looks better on paper. So why do I call this a mistake? Because in many cases, the model isn’t learning the underlying environmental process at all—it’s memorizing location. It is learning how to map lat/lon to the target.]]></summary></entry><entry><title type="html">Locatoin Encoder Earth Embeddings as Priors for Dynamic Air Quality Estimation</title><link href="/preview/pr-48/2025/12/20/earth-embedding-air-pollution.html" rel="alternate" type="text/html" title="Locatoin Encoder Earth Embeddings as Priors for Dynamic Air Quality Estimation" /><published>2025-12-20T00:00:00+00:00</published><updated>2026-02-10T01:33:56+00:00</updated><id>/preview/pr-48/2025/12/20/earth-embedding-air-pollution</id><content type="html" xml:base="/preview/pr-48/2025/12/20/earth-embedding-air-pollution.html"><![CDATA[<p>There has been considerable excitement, along with reasonable amounts of skepticism, around <strong>geospatial foundation models</strong> and so-called <strong>Earth embeddings</strong>. These models promise reusable representations of places learned from large, heterogeneous datasets, and they are increasingly treated as a general-purpose building block for downstream geospatial machine learning tasks. Yet one question kept resurfacing: <strong>what actually happens when static Earth embeddings are used in a higly dynamic estimation problem?</strong></p>

<p>In our paper published in <em>GIScience &amp; Remote Sensing</em>, we explored this question through the lens of <strong>daily surface-level PM2.5 estimation across the continental United States</strong>. This is a particularly demanding setting. Atmospheric transport, wildfire smoke, and weather systems can change rapidly from day to day, and deep-learning-based regression models often struggle not at the mean of the distribution but at its <strong>extremes</strong>—precisely where errors matter most for public health and policy, i.e., highly-polluted days.</p>

<p>At the core of the problem is a familiar but difficult inference task. Satellites observe aerosols as <strong>vertical column measurements</strong>, yet the quantity of interest for exposure and health studies is the <strong>near-surface concentration</strong> of PM2.5, often in locations far from ground monitors (where we live and breathe!). Even with rich Earth observations such as aerosol optical depth (AOD), meteorology, and smoke indicators, learning this mapping remains challenging. Deep learning models frequently achieve strong average performance while systematically underestimating or smoothing away the high-concentration tail of the distribution.</p>

<p>Most Earth embeddings proposed to date have been evaluated on relatively <strong>static or temporally smoothed targets</strong>, including long-term air temperature, biomass, land cover, or species distributions. These benchmarks are valuable, but they do not fully probe how static representations behave when embedded in a <strong>dynamic, nonlinear estimation problem</strong> where rare extremes make up the bulk of error. This gap motivated us to ask whether Earth embeddings can help in settings where temporal variability drives the signal.</p>

<p>A key conceptual insight from our experiments is that <strong>Earth embeddings are most effective when treated as priors rather than as additional features</strong>. Instead of concatenating embeddings to the input and allowing the model to memorize location-specific relationships, we conditioned a strong <strong>Bi-LSTM with attention</strong> on <strong>pretrained, frozen Earth embeddings</strong> using a simple <strong>Hadamard (element-wise) fusion</strong>. Framed differently, the model is encouraged to ask: <em>given what we know about this place, how should today’s observations be interpreted?</em> This conditioning mechanism allows static geographic context to modulate the interpretation of dynamic satellite and meteorological signals.</p>

<p>The architecture used in our experiments is shown below, illustrating how the Earth embedding interacts multiplicatively with the temporal representation learned from Earth observations:</p>

<p><img src="https://res.cloudinary.com/dz3zgmhnr/image/upload/v1770494933/Bi-LSTM_Fusion_lz3ynz.png" alt="Model architecture with Hadamard fusion" /></p>

<p>One of the more surprising results was that this prior-conditioning strategy improved performance <strong>even during highly dynamic events</strong>, including wildfire smoke episodes. In particular, we observed consistent gains at the <strong>high-concentration tail of the PM2.5 distribution</strong>, where deep learning regression models typically degrade despite access to rich inputs such as AOD and meteorology. Seeing improvements in extreme-value behavior—rather than just marginal gains in average error—was both unexpected and encouraging.</p>

<p>The figure below illustrates an example from the <strong>Dixie Fire</strong>, where conditioning on <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/1b57aaddf85ab01a2445a79c9edc1f4b-Abstract-Conference.html">GeoCLIP</a> Earth embeddings leads to markedly better recovery of high PM2.5 concentrations compared to an otherwise identical model without such conditioning:</p>

<p><img src="https://res.cloudinary.com/dz3zgmhnr/image/upload/v1770495204/Dixie_Fire_Pred_woWSD-min_ak9k7g.png" alt="Dixie Fire PM2.5 estimation comparison" /></p>

<p>Another notable finding emerged from comparing different sources of Earth embeddings. In the context of air-pollution estimation, <strong>ground-level imagery–based embeddings (GeoCLIP)</strong> consistently outperformed <strong>satellite-imagery–based embeddings (<a href="https://ojs.aaai.org/index.php/AAAI/article/view/32457">SatCLIP</a>)</strong>. This likely reflects the kinds of signals PM2.5 estimation depends on, including built environment characteristics, infrastructure, and proxies for human activity, which are often more directly captured by ground-level imagery. At the same time, this result highlights an important open question for the field: we need more controlled comparisons of Earth embeddings that differ <em>only</em> in imagery source, rather than also differing in positional encoding, embedding dimensionality, or training objective.</p>

<p>To ground these conceptual insights empirically, we systematically evaluated four geolocation strategies within a unified Bi-LSTM + attention framework: no geolocation, raw latitude/longitude, sinusoidal latitude/longitude, and pretrained Earth embeddings. Across both within-region and out-of-region spatial evaluation schemes, a consistent pattern emerged. Naive coordinate encodings can improve interpolation but often harm generalization, whereas Earth embeddings—particularly when fused via Hadamard product—improve both accuracy and geographic transferability. These results reinforce the interpretation of Hadamard fusion as a mechanism for <strong>conditioning dynamic Earth-observation models on geographic priors</strong>, rather than simply adding more predictors.</p>

<p>Taken together, these findings suggest a broader takeaway. <strong>Earth embedding foundation models are more than representations of place</strong>. When used appropriately, they act as a mechanism for injecting <strong>geographic prior knowledge</strong> into dynamic inference, stabilizing predictions and improving performance in rare but large extremes. This perspective matter in how Earth embeddings might be used in environmental machine learning, especially for applications where extremes matter more than averages.</p>

<p>The full paper, <em>Performance and generalizability impacts of incorporating location encoders into deep learning for dynamic PM2.5 estimation</em>, is available in <em>GIScience &amp; Remote Sensing</em> (Karimzadeh, Wang, &amp; Crooks, 2025):
<a href="https://doi.org/10.1080/15481603.2025.2594797">https://doi.org/10.1080/15481603.2025.2594797</a></p>

<p>Code to reproduce the experiments is available at:
<a href="https://github.com/geohai/PM2.5_CONUS_LSTM">https://github.com/geohai/PM2.5_CONUS_LSTM</a></p>

<p>This work was made possible by a close collaboration with <strong>Zhongying Wang</strong>, our outstanding doctoral student who led much of the modeling effort, and <strong>James Crooks</strong>, whose expertise in health-relevant exposure modeling motivated the work, but also whose intimate knowledge of PM2.5 formation and EPA sensing helped us set up the modeling pipline and the framing of PM2.5 estimation throughout the study.</p>]]></content><author><name>morteza-karimzadeh</name></author><category term="spatiotemporal" /><category term="machine learning" /><category term="remote sensing" /><category term="public health" /><category term="air pollution" /><category term="foundation model" /><category term="earth embeddings" /><summary type="html"><![CDATA[There has been considerable excitement, along with reasonable amounts of skepticism, around geospatial foundation models and so-called Earth embeddings. These models promise reusable representations of places learned from large, heterogeneous datasets, and they are increasingly treated as a general-purpose building block for downstream geospatial machine learning tasks. Yet one question kept resurfacing: what actually happens when static Earth embeddings are used in a higly dynamic estimation problem?]]></summary></entry><entry><title type="html">Forecasting the Geographic Incidence of COVID-19 How Does Social Media Help?</title><link href="/preview/pr-48/2022/06/01/social-media-for-covid-forecast.html" rel="alternate" type="text/html" title="Forecasting the Geographic Incidence of COVID-19 How Does Social Media Help?" /><published>2022-06-01T00:00:00+00:00</published><updated>2026-02-10T01:33:56+00:00</updated><id>/preview/pr-48/2022/06/01/social-media-for-covid-forecast</id><content type="html" xml:base="/preview/pr-48/2022/06/01/social-media-for-covid-forecast.html"><![CDATA[<p>Forecasting COVID-19 geographic spread is a challenging task. Reliable forecasting is crucial, as it is used in resource allocation and allows local authorities and health officials to implement timely interventions.</p>

<p>In these studies, we show that AI-based short term forecasting of COVID-19 can outperform conventional compartmental models that have been long used in epidemiological modeling. These traditional models, to a large extent, failed to reliably predict the local surges in the US. This was partially responsible for the reactive planning of local governments only after a local surge was underway.  Deep learning is data-driven, and successfully models the variations within US counties, from population demographics, to masking and social distancing adherence,  to varying levels of immunity due to vaccination or waning immunity over time. 
Additionally, in our work, we show that social media connectedness can be successfully used to model the spatial diffusion of the disease. In other words, we used data created from social media friendship networks to estimate the amount of transmission from one area to another. Specifically, we used Metas’ (Facebook’s) Social Connectedness Index, an index that quantifies the proportion of users in county-pairs (or state-pairs) that are friends on Facebook. Building on this dataset, our deep learning models incorporate the rate of between-county and between-state transmission of COVID-19, and thus, improve the forecasts.</p>

<p>Our (Nature Com) study also found that Social Media Connectedness is usually a better measure for quantifying human interactions compared to cell phone-driven movement data, which passively monitors the number of cell phones (and thus, people carrying them) that move from one area to another. We hypothesize that the predictive power of social media data over cell phone movement data for quantifying disease transmission may say something about human behavior: people may mask up and social distance when they go to work or shop, but may not adhere to social distancing or masking when spending time with friends. However, this is only a hypothesis and needs more investigation. Our goal is forecasting for all counties, and we can only look at the predictive power of variables, but not make an inference about their precise significance. In short, social media data is a good metric for measuring the amount of human interaction, and this dataset is available for more than 35 countries, even in data-poor regions of the world, where cell-phone mobility datasets are not readily available. Additionally, many US cell phone companies shut down their (free) publication of movement data early in 2021 after vaccines emerged.</p>

<p>Building on our findings, we have been contributing to national forecasting efforts. Every week, teams around the country, including us (representing CU Boulder), use the latest data and generate short-term forecasts and contribute to the central repository of the US COVID-19 Forecast Hub. The Hub, generates an ensemble of all these forecasts, which the CDC then uses in reporting, communications and publications. As the cases of COVID-19 decline, we are all wary of new variants and these forecasting efforts will continue. There is new emphasis on hospitalization forecasts as a better metric for the impact of the virus, and thus, we will continue to contribute daily hospitalization forecasts to the Hub as well.</p>]]></content><author><name>morteza-karimzadeh</name></author><category term="spatiotemporal" /><category term="machine learning" /><category term="COVID-19" /><category term="public health" /><category term="epidemiology" /><summary type="html"><![CDATA[Forecasting COVID-19 geographic spread is a challenging task. Reliable forecasting is crucial, as it is used in resource allocation and allows local authorities and health officials to implement timely interventions.]]></summary></entry></feed>